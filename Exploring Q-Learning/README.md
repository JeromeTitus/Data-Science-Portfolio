# Exploring the Q-Learning Algorithm

This project investigates Q-learning across a host of different environments, ranging from basic to advanced. The notebooks are segmented into two parts:

* __Part 1: Basic__

Q-Learning is implemented in a "constructed" environment using a customized version of Prim's algorithm. Here, the agent acts as an Uber taxi driver, with its task being to pick up and drop-off
passengers in the shortest time possible. A comparative study of different policies was performed - with optimal results obtained with the Upper Confidence Bound policy.

* __Part 2: Advanced__

This part investigates deep Q-learning: an advanced implementation of the algorithm used in more complex environments. Improvments to this advancement are considered: double deep Q-learning and dueling deep Q-learning. A thorough analysis of results is provided, with results being compared across all models built. 
